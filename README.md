# ğŸš— Sentiment Analysis BERT Model â€” FYP

A **BERT-based sentiment analysis model** fine-tuned on an **Uber reviews dataset**, developed as part of the Final Year Project (FYP) for an **AI-based Transport App** at the **National University of Modern Languages (NUML)**.

---

## âœ¨ Overview

This project fine-tunes a pre-trained **BERT (Bidirectional Encoder Representations from Transformers)** model to classify user sentiments from Uber ride reviews. The model is designed to integrate into a university transport application, enabling real-time feedback analysis to improve service quality.

---

## ğŸ¯ Key Features

| Feature | Description |
|---|---|
| ğŸ§  **BERT Fine-Tuning** | Transfer learning on a pre-trained BERT model for domain-specific sentiment classification |
| ğŸ“Š **Uber Reviews Dataset** | Trained on real-world Uber ride review data for practical relevance |
| ğŸ·ï¸ **Sentiment Classification** | Classifies reviews into sentiment categories (e.g., Positive, Negative, Neutral) |
| ğŸ“ **University FYP** | Developed as part of an AI-based transport application for NUML |
| ğŸ **Pure Python** | Entire pipeline implemented in Python |

---

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.x
- **Deep Learning Framework**: PyTorch / TensorFlow
- **NLP Model**: BERT (`bert-base-uncased` or similar)
- **Libraries**: Hugging Face Transformers, scikit-learn, Pandas, NumPy, Matplotlib
- **Environment**: Jupyter Notebook

---

## ğŸ“ Project Structure

```
MODEL_FYP.ipynb/
â”œâ”€â”€ MODEL_FYP.ipynb        # Main notebook â€” data loading, preprocessing, BERT fine-tuning, evaluation
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Jupyter Notebook or JupyterLab
- GPU recommended for faster training (Google Colab works great)

### 1. Clone the Repository

```bash
git clone https://github.com/Ahmedimtiaz-github/MODEL_FYP.ipynb.git
cd MODEL_FYP.ipynb
```

### 2. Install Dependencies

```bash
pip install transformers torch torchvision pandas numpy scikit-learn matplotlib tqdm
```

### 3. Run the Notebook

```bash
jupyter notebook MODEL_FYP.ipynb
```

Or open in **Google Colab** for GPU-accelerated training.

---

## ğŸ“ˆ Model Pipeline

```
Uber Reviews Dataset
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Cleaning   â”‚  â† Remove noise, handle missing values
â”‚  & Preprocessing â”‚  â† Tokenization with BERT tokenizer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BERT Model      â”‚  â† Fine-tune pre-trained BERT
â”‚  Fine-Tuning     â”‚  â† Add classification head
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluation      â”‚  â† Accuracy, Precision, Recall, F1-Score
â”‚  & Metrics       â”‚  â† Confusion Matrix
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Sentiment Predictions
   (Positive / Negative / Neutral)
```

---

## ğŸ“Š Evaluation Metrics

The model is evaluated using standard NLP classification metrics:

- **Accuracy** â€” Overall correctness
- **Precision** â€” Positive predictive value
- **Recall** â€” Sensitivity / True positive rate
- **F1-Score** â€” Harmonic mean of precision and recall
- **Confusion Matrix** â€” Visual breakdown of predictions

---

## ğŸ“ About the Project

This model is a core component of an **AI-based university transport application** developed as a Final Year Project at **NUML (National University of Modern Languages)**. The sentiment analysis module processes user feedback on transport services, enabling:

- ğŸ“‹ Automated review classification
- ğŸ“ˆ Service quality monitoring
- ğŸ”” Alert generation for negative sentiment trends
- ğŸ“Š Dashboard-ready sentiment summaries

---

## ğŸ¤ Author

**M. Ahmed Imtiaz**
- GitHub: [@Ahmedimtiaz-github](https://github.com/Ahmedimtiaz-github)
- University: National University of Modern Languages (NUML)